{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/arnavmdas/epiphany.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uCKcxBHZXHp",
        "outputId": "ba009d36-d1d5-4d0c-8c43-64b5602df533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'epiphany'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 65 (delta 17), reused 37 (delta 8), pack-reused 6\u001b[K\n",
            "Unpacking objects: 100% (65/65), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NUJ7LPHZSIo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "##########################\n",
        "#    Loading packages    #\n",
        "##########################\n",
        "\n",
        "# 1. Load packages\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch import randn\n",
        "from torch.nn import MSELoss\n",
        "import torch.optim as optim\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "!pip install hickle\n",
        "import hickle as hkl\n",
        "from torch.autograd import Variable\n",
        "import gzip\n",
        "import sys\n",
        "import os \n",
        "from sklearn.decomposition import TruncatedSVD, PCA\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "!pip install pyBigWig\n",
        "import pyBigWig\n",
        "\n",
        "# 2. Load data - part 2\n",
        "\n",
        "!wget https://s3.amazonaws.com/hicfiles.tc4ga.com/public/juicer/juicer_tools_1.22.01.jar\n",
        "!wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/genes/hg38.refGene.gtf.gz\n",
        "!gunzip /content/hg38.refGene.gtf.gz\n",
        "\n",
        "chrom_list = [\"chr\"+str(i) for i in range(1,23)] #for human hg38\n",
        "length_list = [248956422,242193529,198295559,190214555,181538259,170805979,159345973,145138636,\n",
        "               138394717,133797422,135086622,133275309,114364328,107043718,101991189,90338345,\n",
        "               83257441,80373285,58617616,64444167,46709983,50818468]\n",
        "chrom_len_dict = dict(zip(chrom_list,length_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained model \n",
        "\n",
        "- Pretrained on GM12878 cell line\n",
        "- Predicts Hi-C contact matrices at 10Kb resolution. "
      ],
      "metadata": {
        "id": "BN9TBsvAZwav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/epiphany/downstream/utils\n",
        "from model_architecture_util import * \n",
        "\n",
        "%cd /content/epiphany/\n",
        "!mkdir pretrained\n",
        "%cd pretrained\n",
        "!wget -O pretrained_GM12878.pt_model https://wcm.box.com/shared/static/vv8xzxnurfk8ddjwuc9evkhapl6fj0tu.pt_model\n",
        "\n",
        "#Load model \n",
        "wsize = 14000\n",
        "net = Net(window_size=wsize)\n",
        "restore(net,'/content/epiphany/pretrained/pretrained_GM12878.pt_model')\n",
        "net.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXeSuMgBZ0BM",
        "outputId": "3b79b95a-1e08-4f2e-cd87-0ed40f489cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/epiphany/downstream/utils\n",
            "/content/epiphany\n",
            "/content/epiphany/pretrained\n",
            "--2022-06-10 01:31:51--  https://wcm.box.com/shared/static/vv8xzxnurfk8ddjwuc9evkhapl6fj0tu.pt_model\n",
            "Resolving wcm.box.com (wcm.box.com)... 107.152.29.197\n",
            "Connecting to wcm.box.com (wcm.box.com)|107.152.29.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/vv8xzxnurfk8ddjwuc9evkhapl6fj0tu.pt_model [following]\n",
            "--2022-06-10 01:31:51--  https://wcm.box.com/public/static/vv8xzxnurfk8ddjwuc9evkhapl6fj0tu.pt_model\n",
            "Reusing existing connection to wcm.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://wcm.app.box.com/public/static/vv8xzxnurfk8ddjwuc9evkhapl6fj0tu.pt_model [following]\n",
            "--2022-06-10 01:31:51--  https://wcm.app.box.com/public/static/vv8xzxnurfk8ddjwuc9evkhapl6fj0tu.pt_model\n",
            "Resolving wcm.app.box.com (wcm.app.box.com)... 107.152.29.201\n",
            "Connecting to wcm.app.box.com (wcm.app.box.com)|107.152.29.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl2.boxcloud.com/d/1/b1!15kP-c0ZS34VpLJa8eiv7ArYSOfW5o-txoYjJCxskOaoTGMMH_brdwm5qTdnSNmMqs5eoAgdZa8RszmAFmuNHZFp7Qr4PIMZsLeWzZ3JTsbZPaBBaex4nI17Qz_M-1jwKGPZddRFZrx9jMqkDFOE6J6M5re6uqHbV5VAF3x8Lf74OJsqi9wh_5r2mj89I7Ht5uLAlVxDFfEHAPYPvpC0KwdYKXC4nbzWge6dQXU3e6S0Cn0uJHXKpsHmtaoGo2IviI8Sw8OcvYNlKFowQ721P-65Bo2OsIAkULtKqvs-vE_BaT6a5ZfAwxnDXAu7ck7xcRTlwajdjmdz7_rYrymch1Zdk-D1E4Ksg404DzMXephuqQT7OZgTbcnSzeZ5mVRThsOB1eQFUIWcvYQszfLjHGLDXWwkM7njuKwqgZX1elNtU58DAld69j1U2tH2e9o1PnWUaU7DeE2D57UPBR_yBzyoXBobiLE86AIm1jtCj95fM5qyJRndkY_WbCDVQ2CI0y8J51nErqvZvtT0FB89TVSkExUd2HOQYYPAui1qwxuJZ_sCoA0oxTDDMDoSoIxBf4Lgki07iQ5jXJy32aX-BVtJd6rIm3pHfBsOj5BqG35ukEBNn4_t2VQdZslBDnQtF9aqyVbSA1L7xAumVrA2BAD9rxETWZz9D2iAThNq2LRk_vS2jn3mPbO1ZqLE4jqRA4SxTVRN5-sHLefN-QABbiquvkDrQ3TuJsxgz8MNv3-lCy1KOKK82M8GXxsHWFjueIDFRZPSZGunLOpzHlPyuTkcB6H74st8cxigIHeBUA3k2F_dZ1RvNTE1qIAtzPvKO9XrSdvSVLWtu6aDNtD3dIRBUnlWDgoDyqrzg0anIlM9FZPU5ux5T7nWP2zchZCyuH0DQ24xOZAxvvVg0kS8amrarl6Utar8KzszldGGoWNlVjNj_vGrqoBw8eW5IW0b8ykPmYu_UX-cFc_GCkBCjvJ5x3AOur_p_PfOl9JMVIB8dinUvlpuRw1j1PFxz0UYb0gAkfKBXDwUe6rz6Nm1BuRwpRcEyoPJ-uPuB0eXbldvpy1vnJZuXEPVtjkoiwo_BSOTgnI_m5XFBlteUjq6UIIpvzG9mLvoFhcRD9MEtbk5N5B0DP_NFVD42f1VYgeNOE5WQKk8oB-8aFDUhHV1X8A20TxP_EQ_bKVtW3MDbv0AWqtc1kY2wyckx21V9genJOxXPkAtdP0xmPxNmWlhDLw8pGCJeyH3G7aiDxq35imZa61-j9_3tyVwaBeuQ1Uuy5BCyV7aKDPhAujanTtSa8e4z4Pyaxz5eYFgZtfIzd77Ih6qXE9M16Nhq-d1e3hv7UBzE2M195eyVKrB8SLHmcAfBu9DfBFVwVGEXftOt1MuOBSnR06pCSB8/download [following]\n",
            "--2022-06-10 01:31:51--  https://dl2.boxcloud.com/d/1/b1!15kP-c0ZS34VpLJa8eiv7ArYSOfW5o-txoYjJCxskOaoTGMMH_brdwm5qTdnSNmMqs5eoAgdZa8RszmAFmuNHZFp7Qr4PIMZsLeWzZ3JTsbZPaBBaex4nI17Qz_M-1jwKGPZddRFZrx9jMqkDFOE6J6M5re6uqHbV5VAF3x8Lf74OJsqi9wh_5r2mj89I7Ht5uLAlVxDFfEHAPYPvpC0KwdYKXC4nbzWge6dQXU3e6S0Cn0uJHXKpsHmtaoGo2IviI8Sw8OcvYNlKFowQ721P-65Bo2OsIAkULtKqvs-vE_BaT6a5ZfAwxnDXAu7ck7xcRTlwajdjmdz7_rYrymch1Zdk-D1E4Ksg404DzMXephuqQT7OZgTbcnSzeZ5mVRThsOB1eQFUIWcvYQszfLjHGLDXWwkM7njuKwqgZX1elNtU58DAld69j1U2tH2e9o1PnWUaU7DeE2D57UPBR_yBzyoXBobiLE86AIm1jtCj95fM5qyJRndkY_WbCDVQ2CI0y8J51nErqvZvtT0FB89TVSkExUd2HOQYYPAui1qwxuJZ_sCoA0oxTDDMDoSoIxBf4Lgki07iQ5jXJy32aX-BVtJd6rIm3pHfBsOj5BqG35ukEBNn4_t2VQdZslBDnQtF9aqyVbSA1L7xAumVrA2BAD9rxETWZz9D2iAThNq2LRk_vS2jn3mPbO1ZqLE4jqRA4SxTVRN5-sHLefN-QABbiquvkDrQ3TuJsxgz8MNv3-lCy1KOKK82M8GXxsHWFjueIDFRZPSZGunLOpzHlPyuTkcB6H74st8cxigIHeBUA3k2F_dZ1RvNTE1qIAtzPvKO9XrSdvSVLWtu6aDNtD3dIRBUnlWDgoDyqrzg0anIlM9FZPU5ux5T7nWP2zchZCyuH0DQ24xOZAxvvVg0kS8amrarl6Utar8KzszldGGoWNlVjNj_vGrqoBw8eW5IW0b8ykPmYu_UX-cFc_GCkBCjvJ5x3AOur_p_PfOl9JMVIB8dinUvlpuRw1j1PFxz0UYb0gAkfKBXDwUe6rz6Nm1BuRwpRcEyoPJ-uPuB0eXbldvpy1vnJZuXEPVtjkoiwo_BSOTgnI_m5XFBlteUjq6UIIpvzG9mLvoFhcRD9MEtbk5N5B0DP_NFVD42f1VYgeNOE5WQKk8oB-8aFDUhHV1X8A20TxP_EQ_bKVtW3MDbv0AWqtc1kY2wyckx21V9genJOxXPkAtdP0xmPxNmWlhDLw8pGCJeyH3G7aiDxq35imZa61-j9_3tyVwaBeuQ1Uuy5BCyV7aKDPhAujanTtSa8e4z4Pyaxz5eYFgZtfIzd77Ih6qXE9M16Nhq-d1e3hv7UBzE2M195eyVKrB8SLHmcAfBu9DfBFVwVGEXftOt1MuOBSnR06pCSB8/download\n",
            "Resolving dl2.boxcloud.com (dl2.boxcloud.com)... 74.112.186.128\n",
            "Connecting to dl2.boxcloud.com (dl2.boxcloud.com)|74.112.186.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 366714931 (350M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_GM12878.pt_model’\n",
            "\n",
            "pretrained_GM12878. 100%[===================>] 349.73M  13.2MB/s    in 27s     \n",
            "\n",
            "2022-06-10 01:32:20 (12.7 MB/s) - ‘pretrained_GM12878.pt_model’ saved [366714931/366714931]\n",
            "\n",
            "Restoring:\n",
            "conv1.conv.weight -> \ttorch.Size([70, 5, 17]) = 0MB\n",
            "conv1.conv.bias -> \ttorch.Size([70]) = 0MB\n",
            "conv2.conv.weight -> \ttorch.Size([90, 70, 7]) = 0MB\n",
            "conv2.conv.bias -> \ttorch.Size([90]) = 0MB\n",
            "conv3.conv.weight -> \ttorch.Size([70, 90, 5]) = 0MB\n",
            "conv3.conv.bias -> \ttorch.Size([70]) = 0MB\n",
            "conv4.conv.weight -> \ttorch.Size([20, 70, 5]) = 0MB\n",
            "conv4.conv.bias -> \ttorch.Size([20]) = 0MB\n",
            "rnn1.weight_ih_l0 -> \ttorch.Size([4800, 900]) = 17MB\n",
            "rnn1.weight_hh_l0 -> \ttorch.Size([4800, 1200]) = 23MB\n",
            "rnn1.bias_ih_l0 -> \ttorch.Size([4800]) = 0MB\n",
            "rnn1.bias_hh_l0 -> \ttorch.Size([4800]) = 0MB\n",
            "rnn1.weight_ih_l0_reverse -> \ttorch.Size([4800, 900]) = 17MB\n",
            "rnn1.weight_hh_l0_reverse -> \ttorch.Size([4800, 1200]) = 23MB\n",
            "rnn1.bias_ih_l0_reverse -> \ttorch.Size([4800]) = 0MB\n",
            "rnn1.bias_hh_l0_reverse -> \ttorch.Size([4800]) = 0MB\n",
            "rnn2.weight_ih_l0 -> \ttorch.Size([4800, 2400]) = 46MB\n",
            "rnn2.weight_hh_l0 -> \ttorch.Size([4800, 1200]) = 23MB\n",
            "rnn2.bias_ih_l0 -> \ttorch.Size([4800]) = 0MB\n",
            "rnn2.bias_hh_l0 -> \ttorch.Size([4800]) = 0MB\n",
            "rnn2.weight_ih_l0_reverse -> \ttorch.Size([4800, 2400]) = 46MB\n",
            "rnn2.weight_hh_l0_reverse -> \ttorch.Size([4800, 1200]) = 23MB\n",
            "rnn2.bias_ih_l0_reverse -> \ttorch.Size([4800]) = 0MB\n",
            "rnn2.bias_hh_l0_reverse -> \ttorch.Size([4800]) = 0MB\n",
            "rnn3.weight_ih_l0 -> \ttorch.Size([4800, 2400]) = 46MB\n",
            "rnn3.weight_hh_l0 -> \ttorch.Size([4800, 1200]) = 23MB\n",
            "rnn3.bias_ih_l0 -> \ttorch.Size([4800]) = 0MB\n",
            "rnn3.bias_hh_l0 -> \ttorch.Size([4800]) = 0MB\n",
            "rnn3.weight_ih_l0_reverse -> \ttorch.Size([4800, 2400]) = 46MB\n",
            "rnn3.weight_hh_l0_reverse -> \ttorch.Size([4800, 1200]) = 23MB\n",
            "rnn3.bias_ih_l0_reverse -> \ttorch.Size([4800]) = 0MB\n",
            "rnn3.bias_hh_l0_reverse -> \ttorch.Size([4800]) = 0MB\n",
            "fc.weight -> \ttorch.Size([900, 2400]) = 8MB\n",
            "fc.bias -> \ttorch.Size([900]) = 0MB\n",
            "fc2.weight -> \ttorch.Size([100, 900]) = 0MB\n",
            "fc2.bias -> \ttorch.Size([100]) = 0MB\n",
            "\n",
            "Restored all variables\n",
            "No new variables\n",
            "Restored /content/epiphany/pretrained/pretrained_GM12878.pt_model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): ConvBlock(\n",
              "    (conv): Conv1d(5, 70, kernel_size=(17,), stride=(1,))\n",
              "    (act): ReLU()\n",
              "    (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (do1): Dropout(p=0.1, inplace=False)\n",
              "  (conv2): ConvBlock(\n",
              "    (conv): Conv1d(70, 90, kernel_size=(7,), stride=(1,))\n",
              "    (act): ReLU()\n",
              "    (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (do2): Dropout(p=0.1, inplace=False)\n",
              "  (conv3): ConvBlock(\n",
              "    (conv): Conv1d(90, 70, kernel_size=(5,), stride=(1,))\n",
              "    (act): ReLU()\n",
              "    (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (do3): Dropout(p=0.1, inplace=False)\n",
              "  (conv4): ConvBlock(\n",
              "    (conv): Conv1d(70, 20, kernel_size=(5,), stride=(1,))\n",
              "    (act): ReLU()\n",
              "  )\n",
              "  (pool): AdaptiveMaxPool1d(output_size=45)\n",
              "  (do4): Dropout(p=0.1, inplace=False)\n",
              "  (rnn1): LSTM(900, 1200, batch_first=True, bidirectional=True)\n",
              "  (rnn2): LSTM(2400, 1200, batch_first=True, bidirectional=True)\n",
              "  (rnn3): LSTM(2400, 1200, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=2400, out_features=900, bias=True)\n",
              "  (act): ReLU()\n",
              "  (fc2): Linear(in_features=900, out_features=100, bias=True)\n",
              "  (act2): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ],
      "metadata": {
        "id": "mwAxtG1iMlJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download input epigenomic data for GM12878"
      ],
      "metadata": {
        "id": "LmxNcDszdQFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/epiphany \n",
        "!mkdir bigWig\n",
        "%cd bigWig \n",
        "!wget -O GM12878_CTCF_merge.bigWig https://wcm.box.com/shared/static/d1hzwihi97o9eghcqp03ec5e6rf60gre.bigwig\n",
        "!wget -O GM12878_DNaseI_merge.bigWig https://wcm.box.com/shared/static/hiowh46s1yyps7hx5sk9qt10f62ls0rw.bigwig \n",
        "!wget -O GM12878_H3K27ac_merge.bigWig https://wcm.box.com/shared/static/l60ucwsmbxczuikralm8y6swnex7516q.bigwig\n",
        "!wget -O GM12878_H3K27me3_merge.bigWig https://wcm.box.com/shared/static/te5tx8ygg69q2my9tm8wqlalmtd4am67.bigwig\n",
        "!wget -O GM12878_H3K4me3_merge.bigWig https://wcm.box.com/shared/static/mi9inmxxyhlpqhep2mtviroy02wtnloy.bigwig"
      ],
      "metadata": {
        "id": "W9F28_ymdSlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download HiC-DC+ normalized obs/exp ground truth data\n",
        "\n",
        "Normalized data for each chromosome can be downloaded from the [Box drive](https://wcm.box.com/s/q5k0lm1050lkzigxi1ynh7muv9x2b2mq)"
      ],
      "metadata": {
        "id": "yJskuQmYMptc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/epiphany \n",
        "!mkdir ground_truth\n",
        "%cd ground_truth \n",
        "\n",
        "!wget -O chr3_ground_truth.txt https://wcm.box.com/shared/static/nood2xtxdak9ln50k30yu0kjjolc8r8g.txt "
      ],
      "metadata": {
        "id": "G6kBdG7TM0rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate predictions for a single chromosome\n",
        "\n",
        "The `results_generation` function to generate predicted contact maps (1Mb distance band for the entire chromosome)\n",
        "- chrom: which chromosome to generate\n",
        "- cell_type: find the epigenomic bigWig files for the corresponding cell type\n",
        "- bwfile_dir: the folder where bigWig files for each epigenomic tracks are stored\n",
        "- submatrix_location: location for saving intermediate file (submatrices along the chromosome)\n",
        "- assemble_matrix_location: location for saving intermediate file2 (assembled predicted submatrices along the chromosome)\n",
        "- ground_truth_file: location of the ground truth contact matrices (saved as lists of lists in pickle format)\n",
        "- ground_truth_location: location for saving subset ground truth with consistent coordinates with the predictions\n",
        "- window_size: window size used in the model \n",
        "- seq_length: length of the submatrix along the diagonal\n",
        "- resolution_hic: resolution of the Hi-C contact maps (default is 10kb)\n"
      ],
      "metadata": {
        "id": "aSG_EIqgaDzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/epiphany/downstream/utils\n",
        "from generate_predictions_util import *\n",
        "\n",
        "#2. generate predictions for chromosomes\n",
        "\n",
        "chrom = \"chr3\"\n",
        "print(chrom,datetime.now())\n",
        "results_generation(chrom = chrom, net=net, \n",
        "                    cell_type = \"GM12878\", \n",
        "                    bwfile_dir = \"/content/epiphany/bigWig\",\n",
        "                    submatrix_location = \"/content/intermediate_matrices.txt\", assemble_matrix_location = \"/content/assembled_chromosome.txt\",\n",
        "                    ground_truth_file = '/content/epiphany/ground_truth/chr3_ground_truth.txt', ground_truth_location = \"/content/ground_truth_corresponding_location.txt\", \n",
        "                    window_size = wsize) #normcounts, zvalue, zfull"
      ],
      "metadata": {
        "id": "5lOIzDdcaG1Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}